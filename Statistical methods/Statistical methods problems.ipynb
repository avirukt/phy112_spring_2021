{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Statistical methods problems"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Question 1: Ehrenfests' Fleas"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Learning objectives\n", "In this question you will:\n", "\n", "- study a Markov chain and analyse its properties\n", "- verify the analysed behaviour by comparing to Monte Carlo simulations\n", "- observe the emergence of a second law of thermodynamics\n", "- determine whether the Markov chain is reversible and simulate it backwards in time\n"]}, {"cell_type": "markdown", "metadata": {"flags": ["problems", "solutions"]}, "source": ["\n", "\n", "In 1907, Paul and Tatiana  Ehrenfest introduced a \"dog-flea\" Markov-chain model intended to illuminate diffusion, equilibration, fluctuations, recurrence, the second law of thermodynamics, and even the \"arrow of time.\"  (Between the Ehrenfests' dogs and Schr\u00f6dinger's cat, 20th century physics models did not seem overly kind to these poor pets!)  Paul Ehrenfest was a physicist who had studied under Ludwig Botlzmann in Vienna, and his wife Tatiana Ehrenfest (n\u00e9e Afanasyeva) was a Russian mathematician. They studied and worked in Vienna, G\u00f6ttingen, St. Petersburg, and later Leiden.\n", "\n", "Though quite simple to formulate, the Ehrefests' flea model exhibits interesting behaviors characteristic of more complicated thermodynamic systems.  In 1959, the Polish-American mathematician Mark Kac praised it as \"probably one of the most instructive models in the whole of Physics....\"  (Although Kac himself later introduced a model that in some ways is even better, what is now called the \"Kac ring\" in his honor).\n", "\n", "Here is the setup envisioned by the Ehrenfests.  Suppose there are two dogs\u2014let's call them Alaric ($A$) and Boudicca ($B$)\u2014upon which reside a total of $N$ fleas.  For computational simplicity, you may assume that $N$ is an even number, although this is not really essential.\n", "\n", "While the fleas may look the same to us, they are distinguishable at least to each other,  and so may be assigned unique labels $1, 2, \\dotsc, N$.  Because the population of fleas is supposed fixed, and fleas not residing on $A$ are by assumption to be found on $B$, the microstate at any time $t$ can be specified as the subset $\\mathcal{A} \\in \\{1, \\dotsc, N \\}$ of those fleas which are on dog $A$ at the time $t$.  Equivalently, we can introduce indicator variables $x_1, \\dotsc, x_N$, where $x_j$ assumes the value $1$ if the $j$th flea currently resides on dog $A$, and is $0$ otherwise.\n", "\n", "Since the dogs do not worry about which fleas are bothering them, but only how many, the macrostate can be defined in terms of macroscopic observables consisting of the total number $N$ of fleas (which is conserved), and the net number $n = | \\mathcal{A} | = \\sum\\limits_{j=1}^{N} x_j$ currently residing on dog $A$, where $n \\in \\{ 0, 1, \\dotsc, N \\}$, the remaining $(N - n)$ fleas by assumption being on $B$.\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### 1a. "]}, {"cell_type": "markdown", "metadata": {"flags": ["problems", "solutions"]}, "source": ["\n", "How many microstates $W(n,N)$ correspond to a given \"macrostate\" specified by $n$ and $N$? \n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Write your answer here"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### 1b. "]}, {"cell_type": "markdown", "metadata": {"flags": ["problems", "solutions"]}, "source": ["\n", "For a total of $N$ fleas, how many distinct microstates are there in all?\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Write your answer here"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### 1c. "]}, {"cell_type": "markdown", "metadata": {"flags": ["problems", "solutions"]}, "source": ["\n", "Which macrostate(s) corresponds to the largest number of available flea microstates?"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Write your answer here"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### 1d. "]}, {"cell_type": "markdown", "metadata": {"flags": ["problems", "solutions"]}, "source": ["\n", "For $N = 100$, plot on a logarithmic scale the exact degeneracy factor $W(n,N)$, for $0 \\le n \\le N$.  Then on the same graph, also plot an approximation to $W(n,N)$ using Stirling approximations for all factorials, and on a separate graph, plot the relative error of your approximation.  (Recall that $N$ would be something like $10^{20}$ or even more for a typical thermodynamic system, but $10^{2}$ is already getting large compared to unity).\n", "\n", "NOTE:  keep these values stored in an array for later use. "]}, {"cell_type": "code", "metadata": {}, "source": ["#Write your answer here"], "outputs": [], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": ["### 1e. "]}, {"cell_type": "markdown", "metadata": {"flags": ["problems", "solutions"]}, "source": ["Next we add some dynamics to the dog-flea system.  Every so often, one or the other of the dogs decides to scratch at a flea, prompting that flea to jump from one dog to the other dog. If the chance of a dog being the next to scratch is proportional to the total number of fleas irritating that dog, and if this dog picks a flea at random to try to scratch, this is equivalent to the following simple stochastic procedure:  starting with some distribution of fleas at time step $s = 0$, at each successive time step $s = 1, 2, 3, \\dotsc$, one flea chosen completely at random jumps from its current canine host to the other.  Either we can assume for simplicity that these jumps occur at uniform time intervals, $t_0 = 0, t_1 = \\tau, t_2 = 2 \\tau, \\dotsc$ for some constant $\\tau$ (e.g., one second), or perhaps more realistically, treat the moments in time at which successive jumps occur as a Poisson process, where the time intervals between jumps are taken as exponentially distributed random variables with a mean interval $\\tau$.  The essential behavior will be similar in either scenario, just in the latter case with some additional variation in clock time with respect to number of time-steps.\n", "\n", "In order to study the dynamical behavior and equilibration of this model, a number of simulation approaches are possible.  We could simulate microscopic trajectories (exactly which fleas are where, and when they jump). But this bogs things down keeping tracking of more detailed information than we actually care about\u2014namely how many fleas are where.  So instead, we might simulate macroscopic trajectories $n(t)$ specifying the total number of fleas on dog $A$, but not the identities of the fleas, which are not really of interest.  With enough trajectories, one can also calculate sample statistics.  Or, we can evolve the probability distribution for the different possible values of $n$, or perhaps even just a few low-order moments of this probability distribution (the average and perhaps the variance of $n$).\n", "\n", "Whatever level of description we adopt, calculations are made manageable by the fact that this flea-jumping process defines a discrete-time _Markov chain_ over the macrostates $n = 0, 1, 2, \\dotsc, N$, at successive time-steps $s = 0, 1, 2, \\dotsc$,\n", "where the probabilities over different possible values of $n$ at time step $(s+1)$ depend only on the probabilities at the previous step $s$.  (For a refresher, see [this link](https://github.com/berkeley-physics/supplamental_materials/blob/master/acharman/MCMC.pdf) for more definitions and details regarding Markov chains).  In addition, this is a special type of Markov chain known as a \"birth-death process,\" where the state $n$ can change by at most $\\pm 1$ unit during each time step\u2014these sorts of processes arise often in biology, demography, epidemiology, engineering, computer science, and other fields.\n", "\n", "\n", "Find the transition probabilities $T(n\\rightarrow k)$, i.e. the probability, given that $n$ fleas are on dog $A$, that $k$ fleas are on dog $A$ at the next timestep.\n", "\n", "Let $n_s$ represent the number of fleas that reside on dog $A$ at time step $s$ (just after the most recent jump, and before the next jump to occur between $s$ and $s+1$), and let $P(n_s=n)$ be the probability that $n_s=n$. Use your transition probilities to find and expression for the probabilities $P(n_{s+1}=k)$ for all $k \\in \\{0, \\dotsc, N \\}$, in terms of the probabilities $P(n_s=n)$ (assuming we do not make any additional observations of the fleas during this time).\n", "\n", "HINT:  verify that your update rule ensures that the probabilities remain properly normalized. \n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Write your answer here"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### 1f. "]}, {"cell_type": "markdown", "metadata": {"flags": ["problems", "solutions"]}, "source": ["Plot the transition matrix $T_{ij}=T(i\\rightarrow j)$."]}, {"cell_type": "code", "metadata": {}, "source": ["#Write your answer here"], "outputs": [], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": ["### 1g. "]}, {"cell_type": "markdown", "metadata": {"flags": ["problems", "solutions"]}, "source": ["Given a Markov chain with transition probabilities $T(x\\rightarrow y)$, a distribution $\\pi(x)$ satisfies _detailed balance_ if, for all $x$ and $y$, $$\\pi(x)T(x\\rightarrow y)=\\pi(y)T(y\\rightarrow x).$$ A Markov chain that admits a probability distribution that satisfies detailed balance is known as _reversible_. Show that a distribution which satisifies detailed balance is _stationary_, i.e. $$\\forall x,\\, P(x_s=x)=\\pi(x)\\implies\\forall x,\\, P(x_{s+1}=x)=\\pi(x).$$ Thus $p(x)$ is an equilibrium. In equilibrium, show that $$P(x_{s-1}=x|x_s=y)=P(x_{s+1}=x|x_s=y),$$ which explains why such Markov chains are called reversible."]}, {"cell_type": "markdown", "metadata": {}, "source": ["Write your answer here"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### 1h. "]}, {"cell_type": "markdown", "metadata": {"flags": ["problems", "solutions"]}, "source": ["By starting from a suitable initial distribution $p(n)$, use the transition probabilities you derived to find the final distribution after 1000 timesteps. Plot the final probabilities. Does this look familiar?"]}, {"cell_type": "code", "metadata": {}, "source": ["#Write your answer here"], "outputs": [], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": ["### 1i. "]}, {"cell_type": "markdown", "metadata": {"flags": ["problems", "solutions"]}, "source": ["\n", "Verify that the binomial distribution $\\pi(n) = 2^{-N} \\binom{N}{n} = 2^{-N} \\tfrac{ N!}{n! \\, (N-n)!}$ for $n = 0, 1, \\dotsc, N$ is a stationary distribution for this Markov chain.\n", "\n", "HINT:  show that this distribution satisfies detailed balance.\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Write your answer here"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### 1j. "]}, {"cell_type": "markdown", "metadata": {"flags": ["problems", "solutions"]}, "source": ["\n", "In the equilibrium distribution $\\pi(n)$, what is the mean and standard deviation of $n$?"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Write your answer here"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### 1k. "]}, {"cell_type": "markdown", "metadata": {"flags": ["problems", "solutions"]}, "source": ["For later use, write a routine to draw independent random samples directly from the stationary distribution $\\pi(n)$, for a fixed value of $N$. Compare the speed of your routine to that of `numpy.random.binomial` ([docs](https://docs.scipy.org/doc/numpy-1.14.0/reference/generated/numpy.random.binomial.html)).\n", "\n", "HINT:  two ways to do this come to mind.  One requires one pseudo-random number for each selection of an $n$, but storage of a substantial pre-computed table.  The other requires up to $N$ random numbers per draw of an $n$, but no storage of pre-computed tables.  Decide for yourself which you think is better when (i) we will making many draws, or (ii) we will make only a few draws. "]}, {"cell_type": "code", "metadata": {}, "source": ["#Write your answer here"], "outputs": [], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": ["### 1l. "]}, {"cell_type": "markdown", "metadata": {"flags": ["problems", "solutions"]}, "source": ["An _irreducible_ Markov Chain is one which can go from any state to any other state given enough time. (Note the analogous conditions for reducibility of graphs and matrices.) Such chains are also called _ergodic_. \n", "\n", "It turns out that any irreducible Markov chain on a finite state space will have a _unique_ stationary  probability  distribution $\\pi(x)$,  which  will  have  support  (i.e.,  some  non-zero  probability)  on all  states. Furthermore, the probability of a state returning to itself is 1, and the expected period is finite, and equal to $\\langle T\\rangle=\\frac{1}{\\pi(x)}$.\n", "\n", "Argue why the Ehrenfest Markov chain is irreducible."]}, {"cell_type": "markdown", "metadata": {}, "source": ["Write your answer here"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### 1m. "]}, {"cell_type": "markdown", "metadata": {"flags": ["problems", "solutions"]}, "source": ["A Markov chain is _regular_ if there exists a number $m$ such that one can go from any state to any other state in exactly $m$ steps, i.e. $\\exists m \\,\\text{s.t.}\\,\\forall i,j,\\, (T^m)_{ij}>0$, where $T$ is the transition matrix of the Markov chain. \n", "\n", "It can be shown that any finite, regular Markov chain ls both _positive recurrent_, (meaning that the expected waiting time to return to any state is finite), and _aperiodic_ (meaning that the possible return times to any initial state are always relatively prime). Aperiodicity is of interest because it entails another convergence result.  Specifically,\n", "a positive recurrent Markov chain will satisfy the _equilibration_ condition,\n", "$$\n", "\\pi(x) = \\lim_{n \\to \\infty} P(x_n=x)\n", "$$\n", "for all states $x$, starting from _any_ initial probability distribution $P(x_0)$, if and only if the chain is also aperiodic.\n", "\n", "However, argue why this Markov chain cannot be regular.\n", "\n", "HINT: what happens to the parity (even/oddness) of $n$ at each jump?"]}, {"cell_type": "markdown", "metadata": {"flags": ["problems", "solutions"]}, "source": ["However, while the chain is not regular, it is \"almost\" regular, in the sense that starting from any value of $n$, half of the states are eventually accessible on even time steps, and the other half are eventually accessible after a sufficiently large odd number of time steps. So we can still converge to the unique stationary distribution overall by either averaging over pairs of adjacent time steps, or equivalently, by starting in a probabilistic mixture with equal probabilities attached to even and odd initial conditions."]}, {"cell_type": "markdown", "metadata": {}, "source": ["### 1n. "]}, {"cell_type": "markdown", "metadata": {"flags": ["problems", "solutions"]}, "source": ["Find a _difference equation_ for the _expected_ number of fleas $\\langle n_{s+1}\\rangle$ at time step $s+1$, in terms of the expected number $\\langle n_s \\rangle$ at the previous time step. Verify that in equilibirum $\\langle n_{s+1}\\rangle_\\pi=\\langle n_s\\rangle_\\pi$.\n", "\n", "HINT: either start with the transition probabilities calculated above, or work with conditional averages and the use the principle of total expectation."]}, {"cell_type": "markdown", "metadata": {}, "source": ["Write your answer here"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### 1o. "]}, {"cell_type": "markdown", "metadata": {"flags": ["problems", "solutions"]}, "source": ["\n", "Find a closed-form solution for $\\langle n_s \\rangle$ in terms of the initial condition\n", "$\\langle n_0\\rangle$, and verify that the mean value always converges (exponentially fast!) to the average of the stationary distribution $\\pi(n)$, whenever $N > 2$.\n", "\n", "HINT:  write things in terms of the discrepancy between $n$ and the equilibrium average.\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Write your answer here"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### 1p. "]}, {"cell_type": "markdown", "metadata": {"flags": ["problems", "solutions"]}, "source": ["\n", "Find a similar recursion relation governing the time evolution of the variance\u2014that is, an expression relating the variance at the next time step to the variance and mean at the previous time step. Verify that the variance of the steady-state dirstirbution is constant.\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Write your answer here"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### 1q. "]}, {"cell_type": "markdown", "metadata": {"flags": ["problems", "solutions"]}, "source": ["\n", "Now, let us explore short-time behavior of the chain, characterized by equilibration toward the stationary distribution.\n", "For $N = 100$, starting from the extreme state $n = N$, plot on the same graph (i) the expected value of $n(s)$, (ii) the $\\pm 1$-$\\sigma$ bands, and (iii) one sample trajectory $n(s)$, as a function of the time step $s$, for $0 \\le s \\le 500$.\n", "\n", "Repeat this $10$ different times to get some visual sense of the variation in behavior of individual sample paths.  (For later use, save all of the final states so you can re-start each from where you left off).  Do these sample paths tend to equilibrate at the rate predicted by the low-order moments? \n", "\n"]}, {"cell_type": "code", "metadata": {}, "source": ["#Write your answer here"], "outputs": [], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": ["### 1r. "]}, {"cell_type": "markdown", "metadata": {"flags": ["problems", "solutions"]}, "source": ["Here we can observe the basic logic underlying _diffusion_.  Non-interacting fleas (or molecules, or what-have-you) tend to move from areas of higher concentration to lower concentration, not because of any repulsive force, and not because of some teleological tendency towards balance, but simply because of all the things that could happen, more of them involve particles moving from higher to lower concentration that the reverse.  If fleas jump completely at random, it is more likely that one jumps from the dog with more fleas to the dog with fewer fleas than the reverse, and the difference in probability increases with increasing initial asymmetry in flea populations.\n", "\n", "Once equilibrated, the dog-flea system will exhibit fluctuations about the $n \\approx \\tfrac{N}{2}$, and even _recurrences_ associated with occasional large fluctuations that briefly take the system to what look like out-of-equilibrium conditions, substantially away from $n \\approx \\tfrac{N}{2}$.\n", "\n", "_Continue_ each of the  time series simulated previously, and plot as a function of time step $s$, for $1 \\cdot 10^4 \\le s \\le 5 \\cdot 10^4$, along with the $\\pm 1$-$\\sigma$ bands.  To avoid clutter, plot each time series on a separate graph to get some visual sense of what typical sample paths look like. \n"]}, {"cell_type": "code", "metadata": {}, "source": ["#Write your answer here"], "outputs": [], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": ["### 1s. "]}, {"cell_type": "markdown", "metadata": {"flags": ["problems", "solutions"]}, "source": ["Notice that on longer time-scales, the relaxation or equilibration is under-resolved, and these fluctuations tend to look like brief \"spikes.\"\n", "\n", "To better understand the nature of the fluctuations in this system, consider trios of states at three successive time steps $s-1, s, s+2$.  If the macrostate in the middle happens to be $n$, the triple of states will assume one of the four possible patterns:\n", "1. case-$\\nearrow$: $(n-1, n, n+1)$\n", "2. case-$\\searrow$: $(n+1, n, n-1)$\n", "3. case-$\\wedge$: $(n-1, n, n-1)$\n", "4. case-$\\vee$: $(n+1, n, n+1)$\n", "\n", "Calculate the probabilities of each of these patterns in equilibrium, conditional on the actual middle value $n$.\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Write your answer here"]}, {"cell_type": "markdown", "metadata": {"flags": ["problems", "solutions"]}, "source": ["Notice that $P(\\nearrow\\!|n) = P(\\searrow\\!|n)$ regardless of whether $n \\ge \\tfrac{N}{2}$ or $n \\le \\tfrac{N}{2}$.  This is a reflection of the reversibility of the chain, and means that we are equally likely to find the system on either an upswing or downswing of a fluctuation.\n", "But also notice that $P(\\wedge|n) >  P(\\nearrow\\!|n) = P(\\searrow\\!|n) >  P(\\vee|n)$ when $n > \\tfrac{N}{2}$, but $P(\\wedge|n) < P(\\nearrow\\!|n) = P(\\searrow\\!|n)  <  P(\\vee|n)$ when $n < \\tfrac{N}{2}$.  So it is more likely for the system to turn back toward $\\tfrac{N}{2}$ than to bend further away from it.  In fact, whenever $n \\neq \\tfrac{N}{2}$, the most likely place to be is at a local optimum, poised to turn back toward $n = \\tfrac{N}{2}$.  When $n = \\tfrac{N}{2}$, $P(\\wedge|n) = P(\\nearrow\\!|n) = P(\\searrow\\!|n)= P(\\vee|n)$, i.e. all possibilities are equally likely."]}, {"cell_type": "markdown", "metadata": {}, "source": ["### 1t. "]}, {"cell_type": "markdown", "metadata": {"flags": ["problems", "solutions"]}, "source": ["That being said, the Ehrenfest Markov chain is positive recurrent, so each macrostate will recur with a finite _expected_ waiting time between visits, given by $\\tfrac{\\tau}{\\pi(n)}$.\n", "But these recurrence times can be extremely long.  (Do keep in mind that we are talking here about recurrence times for the _macrostates_ $n$.  The recurrence times for the precise microstates will be much longer still.  However, the variation in the recurrence time can become quite large for for large values of $\\left|n - \\tfrac{N}{2}\\right|$, so the average may not be a particularly good characterization of the observed recurrences).\n", "\n", "\n", "Still considering the case $N = 100$, and supposing jumps happen every second, tabulate  and plot the expected recurrence times, for returns to the macrostates $n = 50, 51, \\dotsc, 100$.   (Why must the statistics for $n$ and $(N-n)$ be the same?)  For comparison, there have been about $4 \\cdot 10^{17}$ seconds in the lifetime of the universe since the Big Bang. \\;\n", "\n", "\n"]}, {"cell_type": "code", "metadata": {}, "source": ["#Write your answer here"], "outputs": [], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": ["### 1u. "]}, {"cell_type": "markdown", "metadata": {"flags": ["problems", "solutions"]}, "source": ["\n", "Also calculate, for a system in equilibrium, the overall unconditional probabilities of each of the four trio patterns, still assuming $N = 100$ (but no longer conditioned on the value of $n$ in the middle of the triple).  \\;\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Write your answer here"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### 1v. "]}, {"cell_type": "markdown", "metadata": {"flags": ["problems", "solutions"]}, "source": ["\n", "\n", "Draw an initial condition at random from $\\pi(n)$, and using a long run consisting of $10^5$ time steps, find:\n", "- the relative frequencies of each of the four distinct trio patterns, centered on each $n = 0, \\dotsc, N$ for which you obtain data,\n", "- the frequencies of each of the four distinct trio patterns overall (irrespective of, i.e., not conditioned on the value of the central $n$),\n", "- the number of recurrences observed for each $n = 0, \\dotsc, N$ (many might be zero),\n", "- the estimated average recurrence times for any $n$ for which recurrences were observed (requiring at least two visits).\n", "\n", "In all cases, compare the observed sample values to the theoretical predictions."]}, {"cell_type": "code", "metadata": {}, "source": ["#Write your answer here"], "outputs": [], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": ["### 1w. "]}, {"cell_type": "markdown", "metadata": {"flags": ["problems", "solutions"]}, "source": ["Because we are interested in equilibration, recurrence, and related issues, we should also take a look at the evolution of the _entropy_ of the dog-flea system. In this regard, it will be important to distinguish the _Boltzmann_ entropy within a \"microcanonical\"-like ensemble, and the _Shannon-Gibbs_ entropy within a \"canonical\"-like ensemble.  In both pictures, the microstates jump around stochastically.  But in a microcanonical-like perspective, we imagine that the macrostate is associated with the actual value of $n(t)$, which somehow remains known over time.  So all of the uncertainty lies in which microstate compatible with a given $n$ the system might happen to reside.  The corresponding entropy is the \"Boltzmann\" entropy $S_B(n,N) = k_B \\log W(n,N)$.  As a function of the fluctuating value of $n$, this entropy $S_B$ can also fluctuate up _or down_. \n", "\n", "But consider instead a more Gibbsian, or canonical-like perspective, where we associate the macrostate not with the actual value of $n(t)$, but with our entire probability distribution over the possible states.  The relevant entropy is then the _Shannon-Gibbs entropy_ $S_G$ measuring the amount of uncertainty as to the microstate of the system. \n", "\n", "The Ehrenfest Markov chain makes explicit reference only to the macroscopic observable $n$, but clearly the dynamics treat the individual fleas symmetrically, so if the distribution over microstates starts off being symmetric under permutations of the flea labels, it will remain so, justifying an assumption that, for a given $n$, all possible assignments of individual fleas to dogs consistent with that $n$ may be regarded as equally likely.\n", "\n", "Suppose we do know $N$ exactly, but may be uncertain about the actual value of $n$ at some time $s$, and so we assign a probability distribution $P(n_s)$ over the various possibilities.  Given that we also always remain maximally uncertain as to which microstate the system occupies amongst all those compatible with whatever we know about the macrostate, this probability $P(n_s=n)$, for each $n$, will be further spread _uniformly_ over all microscopic possibilities compatible with $n$.\n", "\n", "Under these conditions, show that the Shannon-Gibbs entropy, measuring the amount of uncertainty as to the flea microstate, will be given by\n", "$$\n", "S_G(s;N)  = N k_B \\log(2) - k_B \\sum\\limits_{n = 0}^{N} P(n_s=n) \\log \\bigl[  \\tfrac{P(n_s=n)}{\\pi(n)} \\bigr],\n", "$$\n", "where $\\pi(n)$ is the stationary distribution of the Markov chain, as introduced above.  (In the notation, we leave implicit the dependence of $S_G$ on the distribution $P(n_s=n)$).\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Write your answer here"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### 1x. "]}, {"cell_type": "markdown", "metadata": {"flags": ["problems", "solutions"]}, "source": ["Now, suppose $P(n_s)$ and $Q(n_s)$ are any two (non-negative, normalized) macrostate probability distributions (perhaps based on different initial states of knowledge), that separately evolve according to the Markov-chain stochastic dynamics.  Using convexity arguments, it is possible to prove the following relation, a version of what is known as the _data processing inequality_ involving the so-called _relative entropy_ of the distributions:\n", "$$\n", "\\sum\\limits_{n = 0}^{N} P(n_{s+1}=n) \\log \\bigl[  \\tfrac{ P(n_s=n) }{ Q(n_{s+1}=n) } \\bigr] \\le \\sum\\limits_{n = 0}^{N} P(n_s=n) \\log \\bigl[ \\tfrac{P(n_s=n)}{ Q(n_s=n) } \\bigr].\n", "$$\n", "This basically says that \"mixing things up\" by running the Markov chain cannot make it any easier to distinguish observations coming from the two distributions.  That is, under the operation of the stochastic flea-jumping dynamics, the probability distributions tend to look ever more similar as time goes on.  If we then specifically choose $Q(n_s=n) = \\pi(n)$ to be the _stationary_ distribution for the Markov chain, then this distribution remains invariant, in the sense that $Q(n_{s+1}=n) = \\pi(n)$, $Q(n_{s+2}=n) = \\pi(n)$, etc., and hence\n", "$$\n", "\\sum\\limits_{n = 0}^{N} P(n_{s+1}=n) \\log \\bigl[  \\tfrac{ P(n_s) }{ \\pi(n) }  \\bigr] \\le \\sum\\limits_{n = 0}^{N} P(n_s) \\log \\bigl[ \\tfrac{P(n_s) }{ \\pi(n) }  \\bigr],\n", "$$\n", "which implies a \"second law\" for the probability distribution $P(n_s)$, in the form\n", "$$\n", "0 \\le S_G(s; N) \\le S_G(s+1; N) \\le N k_B \\log(2).\n", "$$\n", "Generically, the inequality in the data processing inequality will tend to be strict, such that this entropy converges towards the maximum.  In any event, it can never decrease under the Markov time evolution.\n", "\n", "(Recall that if the initial condition concentrated all of the probability on a single value of $n$,\n", "$P(n_s)$ will only have support on states of opposite parity at successive time steps. But if we plug into the entropy a distribution corresponding to the average over two successive time-steps $\\bar{P}(n_s) = \\tfrac{1}{2}[P(n_s) + P(n_{s+1})]$, a similar inequality still holds).\n", "\n", "Starting from $n = N = 100$, plot on the same graph the Boltzmann entropy $S_B$ of a sample trajectory $n_s$, and the Shannon-Gibbs entropy $S_G$ of the probability distribution $\\bar{P}(n_s) = \\tfrac{1}{2}[P(n_s) + P(n_{s-1})]$, both as a function of the time step $s$, for $1 \\le s \\le 500$, and then on separate graph (at more compressed scale) plot both entropies for $5 \\cdot 10^2 \\le s \\le 5 \\cdot 10^4$. \n", "\n", "Note: for the purposes of calculating the Shannon-Gibbs entropy, we are using the average of the probability distribution over two successive time-steps $\\tfrac{1}{2}[ P(n,s-1) + P(n,s) ]$, in order to get rid of the even/odd oscillation when starting from a single value of $n_0$.\n", "\n"]}, {"cell_type": "code", "metadata": {}, "source": ["#Write your answer here"], "outputs": [], "execution_count": null}, {"cell_type": "markdown", "metadata": {"flags": ["problems", "solutions"]}, "source": ["Notice that when $N \\gg 1$, both $S_B$ and $S_G$ equilibrate towards approximately the same value.  But whereas $S_B$ sometimes fluctuates downward from this value as fluctuations towards large or small values of $n$ happen to occur, $S_G$ asymptotes towards the maximum without ever decreasing, as the probability distribution $P(n_s)$ itself does not exhibit any recurrences, but equilibrates irreversibly toward the stationary distribution.\n", "\n", "The usual interpretation of this different behavior emphasizes the idea of fluctuations, which  are not captured as part of classical thermodynamics proper.  In the Botlzmann picture, macrostates correspond to define, known values of $n$, and equilibrium is associated with the value of $n$ associated with the largest number of microstates, namely $n = \\tfrac{N}{2}$.  But the dynamics lead to fluctuations _about_ this equilibrium, so the second law assumes a statistical character, with entropy non-decrease holding true on average, but subject to fluctuations, which do however become increasingly rare as the size $N$ of the system increases.  In the Gibbs picture, macrostates are associated with probability distributions over $n$, and the resulting entropy of an isolated system never decreases, but there are in effect fluctuations _within_ equilibrium, because it is associated with a probability distribution, or ensemble of possibilities.  This sort fo distinction was emphasized by Martin Klein.\n", "\n", "A better and more \"modern\" explanation would instead focus on information and uncertainty.  Entropy is just a measure of our _lack of information_ about the microstate of the system. The Boltzmann approach really presupposes that we know the value of the macroscopic observable $n(t)$ at all times.  But in order to know the value of a macroscopic variable, either we must measure it initially and be confident that it will remain conserved (as with the energy of an isolated system), or we must repeatedly measure it  as the system evolves in time.\n", "\n", "In the first case, if the macroscopic quantity is conserved so as to avoid the need to re-measure, then it cannot fluctuate, and neither will the corresponding Boltzmann entropy.  Of course, this is not relevant to the Ehrenfest model, because the whole point is that while $N$ is conserved, $n(t)$ is not, instead evolving stochastically.\n", "\n", "In the second case, involving repeated observations, by design each measurement provides _new_ information about the macroscopic observable, and hence can change the entropy we assign to the system.  The entropy can go up or down, because gaining information about macroscopic variables could increase or decrease the uncertainty as to which microstate is occupied.  (Nor can the system remain physically isolated during a measurement, so entropy non-decrease is not required by the second law in such situations).\n", "\n", "If relevant macroscopic observables are not conserved, but also we are making repeated observations, then the appropriate entropy is the Gibbs-Shannon entropy of the time-evolving probability distribution over the states.  As we have seen, this entropy cannot decrease within the Ehrenfest model."]}, {"cell_type": "markdown", "metadata": {}, "source": ["### 1y. "]}, {"cell_type": "markdown", "metadata": {"flags": ["problems", "solutions"]}, "source": ["Finally, let us examine directly the nature of the time-reversed Markov chain.  For every finite macroscopic (or microscopic) trajectory, there is a possible time-reversed trajectory that starts where the former ends and successively undoes each jump.  But this does not necessarily mean the relevant conditional probabilities of these are equal. \n", "\n", "But we can simulate trajectories backwards:\n", "\n", "Using Bayes' rule for conditional probabilities, deduce $P(n_{s-1}=k|n_s = n)$.  You will need to use  a _prior_ probabilities of the macrostate at steps $s-1$ and $s$, unconditional on each other.  In the absence of any other information, one should use the _maximum entropy_ distribution, which is just equal to the stationary distribution."]}, {"cell_type": "markdown", "metadata": {}, "source": ["Write your answer here"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### 1z. "]}, {"cell_type": "markdown", "metadata": {"flags": ["problems", "solutions"]}, "source": ["\n", "Given this rule, and again assuming $N = 100$, simulate and plot trajectories starting at $n(1000) = N$, for $1000 \\ge s \\ge 0$.\n", "\n", "How do these trajectories compare to the actual reversals of the trajectories you simulated ealier?  Explain.\n", "\n"]}, {"cell_type": "code", "metadata": {}, "source": ["#Write your answer here"], "outputs": [], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": ["### 1A. "]}, {"cell_type": "markdown", "metadata": {"flags": ["problems", "solutions"]}, "source": ["Finally, by in effect averaging  the previous rule, one can evolve the entire probability distribution over $n$ backward in time, in the sense of determining $P(n_{s-1})$ for the predecessor states, knowing only $P(n_s)$ at one time\u2014but NOT yet knowing any of the probabilities $P(n_0), \\dotsc P(n_{s-2})$:\n", "\n", "Do this, but \"starting\" (ending?) from a distribution concentrated on the definite state $n(1000) = N$, and plot the Boltzmann entropy and Shannon Gibbs entropy, for $1000 \\ge s \\ge 0$.  Going backward, how does the entropy behave on short-ish time-scales, and on longer time scales? \n"]}, {"cell_type": "code", "metadata": {}, "source": ["#Write your answer here"], "outputs": [], "execution_count": null}, {"cell_type": "markdown", "metadata": {"flags": ["problems", "solutions"]}, "source": ["We should end our exploration with one caveat.  As illuminating as the Ehrenfest model may be, there are some important differences between its dynamics and the underlying microscopic dynamics of ordinary physical systems, differences that might raise concerns of question-begging when it comes to issues regarding equilibration, reversibility, recurrences, and the nature of the second law.  In classical mechanics (and, absent measurement, in quantum mechanics), the microscopic dynamics are deterministic (where the future microstate is uniquely determined by the past microstate), invertible (where the past microstate can be inferred uniquely from a future microstate), and time-reversible (where this inversion can be effected by reversing the velocities of all particles and then using the original equations of motion).  Strictly speaking, none of these properties hold true for the microscopic dynamics of the Ehrenfest model, which are intrinsically stochastic."]}, {"cell_type": "markdown", "metadata": {}, "source": ["---"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Question 2: Monte Carlo Magic Squares"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Learning objectives\n", "In this question you will:\n", "\n", "- apply statistical techniques to solve unrelated problems\n", "- create \"artificial\" systems and analyse them using the same techniques used for \"physical\" systems\n", "- sample from physically relevant statistical distributions\n", "- assess whether a system has equilibrated and estimate the equilibration time\n"]}, {"cell_type": "markdown", "metadata": {"flags": ["problems", "solutions"]}, "source": ["\n", "\n", "A normal _magic square_ of order $n$ is an $n \\times n$ square array in which the successive integers $1, \\dotsc, n^2$ are arranged so that all rows, all columns, and both the main diagonal and anti-diagonal all sum to the same numerical value.\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### 2a. "]}, {"cell_type": "markdown", "metadata": {"flags": ["problems", "solutions"]}, "source": ["\n", "If there is to be an $n \\times n$ magic square, what must be the common sum for any row, column, or diagonal?  This number is known as the _magic constant_ of order $n$.\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Write your answer here"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### 2b. "]}, {"cell_type": "markdown", "metadata": {"flags": ["problems", "solutions"]}, "source": ["\n", "\n", "Argue why there can be no normal magic square of order $2$.\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Write your answer here"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### 2c. "]}, {"cell_type": "markdown", "metadata": {"flags": ["problems", "solutions"]}, "source": ["(It turns out that normal magic squares of all orders $1,3,4,5, \\dotsc$ _other than_ $2$ can be constructed.  Magic squares of order $3$ were known to Chinese mathematicians as far back as around 190 BCE, and order $4$ squares were known to Indian Mathematicians by 587 CE, while magic squares up to order $9$ were reported by Arabic mathematicians by the early middle ages, circa 983 CE).\n", "\n", "Find a normal magic square of order $3$.  You can of course look up the answer, but it might provide more insight if you try to work it out by trial and error.  Apart from overall rotations or reflections of the matrix, there is only one such magic square.\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Write your answer here"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### 2d. "]}, {"cell_type": "markdown", "metadata": {"flags": ["problems", "solutions"]}, "source": ["\n", "As a fun aside, we note that if one places point masses at the center of each cell of any normal magic square, of mass proportional to the integer value associated with the cell, then (i) the center of mass of the resulting mass distribution coincides with its geometric center, and (ii) the moment of inertia with respect to an axis through this center and perpendicular to the plane of the square is the same for all normal magic squares of a given order.\n", "\n", "Using some short Python code, verify that (i) is true for your $3 \\times 3$ square, and then calculate the moment of inertia mentioned in (ii).\n", "\n", "(If you want a more ambitious challenge, you can deduce the general rule for the value of the moment of inertia for normal magic squares of order $n$)."]}, {"cell_type": "code", "metadata": {}, "source": ["#Write your answer here"], "outputs": [], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": ["### 2e. "]}, {"cell_type": "markdown", "metadata": {"flags": ["problems", "solutions"]}, "source": ["It is easy to check whether a square is magic, but harder to find a square that is magic.  There are various deterministic algorithms for generating magic squares, including the bordering method, al-Buzjani's method, the de la Loub\u00e8re's or \"Siam\" method, Euler's method, the Narayana-de la Hire method, Conway's LUX method, Strachey method, etc.  Interested readers can look these up on _Wikipedia_ or elsewhere, but such methods can be quite tedious.\n", "\n", "Instead, here we will try to generate magic squares by a stochastic method, known as _simulated annealing_.  Simulated annealing is a Markov-Chain Monte Carlo (MCMC) technique that is often quite effective at finding good solutions to such _combinatorial optimization_ problems, in analogy to how thermodynamic systems preferentially tend to settle into low-energy states as their temperature is quasi-statically lowered.  If needed, see [this link](https://github.com/berkeley-physics/supplamental_materials/blob/master/acharman/MCMC.pdf) for more details on Markov chains, MCMC, and simulated annealing.\n", "\n", "Specifically, here let $X$ denote the \"microtate\" of the square, thought of as a $n \\times n$ matrix with elements $X_{ij}$ for $i,\\, j \\in \\{1, \\dotsc, n\\}$, with values assigned such that each integer in  $\\{1, \\dotsc, n^2 \\}$ appears once and only once in the matrix.  There are a total of $(n^2)!$ such microstates in all.\n", "\n", "We pretend that the square is a thermodynamic system with some Hamiltonian, or energy function, $H(X)$ that consists of the quantity we seek to optimize\u2014in this case, $H(X)$ should encode deviations from \"magic-squareness,\" such that its \"ground states\" correspond to normal magic squares, but excited states exhibit one or more mismatched row, column, or diagonal sums.\n", "\n", "If we can simulate the system in thermodynamic equilibrium at a fixed temperature $T$, then the probability distribution over the possible microstates will follow a canonical ensemble, with $P(X) = \\tfrac{1}{Z(\\beta)} e^{-\\beta H(X)}$, where $\\beta = \\tfrac{1}{k_B T}$ is the \"coolness\" parameter, and $Z(\\beta)$ is the partition function providing normalization.  As the simulated temperature $T$ decreases, the probability of finding the system in a low-energy state will increase.  So if we can equilibrate the system at very low temperature, we have a good chance of finding the system in a ground state corresponding to a magic square solution.\n", "\n", "Since the total number of microstates can be very large, simulated annealing uses Markov chain Monte Carlo (MCMC) rather than ordinary Monte Carlo to try to equilibrate the system at a given temperature $T$.  That is, rather than trying to sample directly from the Boltzmann distributions, we sample from a Markov chain which converges to the desired Boltzmann distribution.  This avoids having to explicitly sum the partition function $Z(\\beta)$ ahead of time.\n", "\n", " As another trick, the technique does not attempt to equilibrate directly at a very low temperature, because the system can become \"quenched,\" getting stuck near some local minimum in energy for an extremely long time.  Instead, we want to slowly \"anneal\" the system, by starting it off at high temperature, then slowly lowering the temperature such that the system remains near equilibrium as it cools, settling into a low-energy state with increasingly high probability.\n", "\n", "\n", "Write down an effective Hamilton $H(X)$ that (i) is a function of the proposed assignment of integers to positions within the square, (ii) achieves its absolute minimum (for definiteness, let us say with value $H = 0$) when the arrangement constitutes a normal magic square, (iii) increases in some sensible way with increasing deviations from a magic arrangement, and (iv) is invariant with respect to reflections and rotations of the square, which do not really change the intrinsic arrangement of the numbers in relation to each other.  \\;\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Write your answer here"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### 2f. "]}, {"cell_type": "markdown", "metadata": {"flags": ["problems", "solutions"]}, "source": ["\n", "Then, program a function that can (hopefully efficiently) evaluate this Hamiltonian for any allowed microstate $X$. \n", "\n", "HINTs:  The Hamiltonian function will be evaluated many, many times during a simulated annealing run.  Try to make it as efficient as possible.  For example, squaring integers may be faster than taking absolute values, depending on implementation details.  Also give some thought as to how you can best represent the microstate $X$ _in silico_."]}, {"cell_type": "code", "metadata": {}, "source": ["#Write your answer here"], "outputs": [], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": ["### 2g. "]}, {"cell_type": "markdown", "metadata": {"flags": ["problems", "solutions"]}, "source": ["Next we will need to adopt a set of possible transitions between microstates that will be proposed at each step of the Markov chain.  Which transitions we use and wth what probabilities can substantially influence the efficacy of the simulated annealing.  A good set of transitions transitions should (i) be fairly easy to implement, (ii) allow for the possibility of moving between any two microstates after some reasonably manageable (but definitely finite) number of steps; (iii) relatedly, generate an irreducible, reversible, and regular Markov chain (which then has a unique stationary state to which the system will equilibrate); and (iv) hopefully accommodate _incremental_ improvement in typical values of the energy as the temperature is lowered.\n", "\n", "For the magic square problem, some simple choices that come to mind are:\n", "1. scheme $a$: pairwise exchanges of the _contents_ $X_{ij}$ and $X_{i'j'}$ of any two positions  $(i,j)$ and $(i', j')$ in the array $X$, chosen at random;\n", "2. scheme $b$: pairwise exchanges of the _positions_ within the square of a pair of successive integers $k$, $k+1$, where the smaller of these integers is chosen uniformly at random from $1, \\dotsc, n^2-1$;\n", "3. scheme $c$: exchanges of the contents of a pair of randomly chosen rows, or a pair of randomly chosen columns.\n", "\n", "Verify that under schemes $a$, $b$, or $c$, the probability of _proposing_ a transition and proposing the reversed transition are always equal. Therefore all three schemes can be made reversible."]}, {"cell_type": "markdown", "metadata": {}, "source": ["Write your answer here"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### 2h. "]}, {"cell_type": "markdown", "metadata": {"flags": ["problems", "solutions"]}, "source": ["  As for irreducibility, verify that  both scheme $a$ and $b$ lead to irreducible Markov chains, where every state is accessible from any other state after some finite number of (accepted) transitions, but argue why scheme $c$ is not irreducible\u2014and therefore is not suitable for simulated annealing, and need not be considered further.\n", "\n", "HINT:  some property of any initial state will be conserved by this set of transitions, which prevents reaching some other states."]}, {"cell_type": "markdown", "metadata": {}, "source": ["Write your answer here"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### 2i. "]}, {"cell_type": "markdown", "metadata": {"flags": ["problems", "solutions"]}, "source": ["Regarding regularity:  for each order $n$, and each viable proposal scheme $s \\in \\{ a, b,\\}$, let $k^{s}_{n}(X,X')$ be the _minimum_ number of transitions needed to get from microstate $X$ to microstate $X'$.  Obviously, $k^{s}_{n}(X,X) = 0$ for all states and either scheme, whereas \"nearest neighbor\" states (this is with respect to possible transitions, not necessarily anything geometric) have $k^{s}_{n}(X,X') = 1$, \"next nearest neighbors\" have $k^{s}_{n}(X,X') = 2$, etc.\n", "\n", "\n", "For each order $n$, and each transition scheme ($s = $ $a$ or $b$), evaluate  the _maximum_ value of this minimum $k^{s}_{n}(X,X')$ across all pairs of microstates.\n", "\n", "HINT: this is pretty straightforward to deduce in scheme $a$, but somewhat less obvious for scheme $b$ (because only swaps of adjacent integers are allowed)."]}, {"cell_type": "markdown", "metadata": {}, "source": ["Write your answer here"]}, {"cell_type": "markdown", "metadata": {"flags": ["problems", "solutions"]}, "source": ["Starting from a worst-case initial condition, it takes at least this many steps to \"propagate\" probability mass to a targeted final state (assuming proposed transitions have some chance of being accepted).  But also after this number of time steps, the probability will be non-zero for entering  any state having started from any initial state, so the chain will be regular.\n", "(Why?  Once we know probability mass has accrued to some state, there is some chance of it staying there as long as the state is not one of maximum energy.  And once probability begins to be shuffled to the maximum energy state it will continue to propagate there, because all other states remain occupied with some probability.)."]}, {"cell_type": "markdown", "metadata": {}, "source": ["### 2j. "]}, {"cell_type": "markdown", "metadata": {"flags": ["problems", "solutions"]}, "source": ["In simulated annealing, at each time step, after _proposing_ a transition stochastically according to a scheme like that above, the transition is then _accepted_ or _rejected_ according to another rule that guarantees the process eventually converges in distribution to the canonical distribution.  The simplest is perhaps the Metropolis-Hastings prescription, which always accepts the proposed transition if it lowers the energy, but sometimes accepts the proposal even if it raises the energy\u2014namely with \"Arrhenius\" probability $e^{- \\beta \\bigl( H(X') - H(X) \\bigr) }$ assuming the proposed transition and the timer-reversed transition are equally likely.\n", "\n", "Explain which of the two transition proposal schemes is expected to work better, at least at low temperatures), and why. \n", "\n", "HINT:  Scheme $a$ seems like it cold lead to faster mixing, becasue arbitrary states can be reached in a fewer number of steps.  But keep in mind that (i) rejected steps will take just as much computation time as accepted steps, and (ii) only a small fraction of the possible steps in schemes $a$ will have appreciable chance of being accepted once the temperature is low.\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Write your answer here"]}, {"cell_type": "markdown", "metadata": {"flags": ["problems", "solutions"]}, "source": ["Note: for purposes of  run-time efficiency,  it will be convenient to maintain two different (but synchronized) representations of the microstate\u2014the integer values as a function of the sorted cell positions, and the cell positions as a function of the sorted integers.  A bit of extra storage will pay off in speed here.\n", "\n", "Another note:  If you were really aiming to maximize efficiency of the running of the code (not the writing of it), then you might consider a hybrid scheme which sometimes draws from on set of transitions and sometimes the other, with the probability dependent on temperature.  But that seems like overkill here."]}, {"cell_type": "markdown", "metadata": {}, "source": ["### 2k. "]}, {"cell_type": "markdown", "metadata": {"flags": ["problems", "solutions"]}, "source": ["After  imagining doing all of this at some fixed temperature, in order  to nudge the system toward its ground state, we will need a cooling schedule, where we simulate at a fixed temperature $T$ for a while, then lower the temperature a bit, and then repeat as the system hopefully settles preferentially in lower and lower energy states.\n", "\n", "\n", "_Roughly estimate_ the energy $E_t$ of a typical or randomly chosen microstate (relative to the ground state which was set at $E = 0$.).\n", "\n", "HINT:  As we are just looking for an approximation, you can ignore _correlations_ between the various row and column totals.  "]}, {"cell_type": "markdown", "metadata": {}, "source": ["Write your answer here"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### 2l. "]}, {"cell_type": "markdown", "metadata": {"flags": ["problems", "solutions"]}, "source": ["If we start out at sufficiently high temperature, where, say, $k_B T \\approx 20\\, E_t$,  most of the proposed transitions should be accepted, and we will effectively \"melt' the system and randomize the microstate.\n", "\n", "Determine the energy $E_1$ of the first excited states (relative to the ground state). \n", "\n", "HINT:  You should actually be able to evaluate this excitation energy exactly, without too much trouble."]}, {"cell_type": "markdown", "metadata": {}, "source": ["Write your answer here"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### 2m. "]}, {"cell_type": "markdown", "metadata": {"flags": ["problems", "solutions"]}, "source": ["If we gradually cool the system from its initial, high temperature down to a sufficiently low temperature, say to where $k_B T \\approx \\tfrac{1}{4} E_1$, then with reasonably high probability we should find the system occupying the grounds state.\n", "\n", "The problem is to figure out how slowly to cool\u2014or more specifically, how many iterations to remain trying to equilibrate at a given temperature $T$, and then by what amount  $\\Delta T$ we should decrease the temperature.  Going more slowly is beneficial from the point of view of converging to the desired minimum, but is of course more costly in terms of total computation.  Refer to [this link](https://github.com/berkeley-physics/supplamental_materials/blob/master/acharman/MCMC.pdf) for some suggestions.\n", "\n", "Finally, it will be useful to keep track of a number of statistics, including the average and RMS energy (after some amount of  \"burn-in\" time) at each simulated temperature; the number of proposed and accepted transitions at the current temperature, and the lowest-energy configurations found so far at the current temperature and throughout the entire simulation; and the total amount of run time. (To make the interpretation of this data easier, it makes sense here to use a discrete strategy, i.e. spend some number of steps at constant temperature instead of changing it slowly every step.)\n", "\n", "Implement all of these features in a code that performs simulated annealing to seek magic squares of a size $n$ prescribed by the user.  Suitably parameterize the cooling schedule so that you can experiment with different ideas. \n", "1. First, find the third order magic square. Verify that it is the correct solution. \n", "2. Then, try to find a sixth order magic square. \n", "3. What is the highest-order magic square you can find? \n", "\n", "Plot the average energy, temperature, and proportion of transitions accepted as a function of the time-step . (To cut down on the data, you may sub-sample the time-steps)."]}, {"cell_type": "code", "metadata": {}, "source": ["#Write your answer here"], "outputs": [], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": ["### 2n. "]}, {"cell_type": "markdown", "metadata": {"flags": ["problems", "solutions"]}, "source": ["\n", "For a (hopefully successful) simulated annealing run, plot estimates for the average energy, heat capacity, and entropy as a function of temperature. Also plot the transition acceptance probability as a function of temperature.\n", "\n", "Hint: instead of finding the heat capacity by finite differencing, estimate it using the variance of the energy."]}, {"cell_type": "code", "metadata": {}, "source": ["#Write your answer here"], "outputs": [], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": ["### 2o. "]}, {"cell_type": "markdown", "metadata": {"flags": ["problems", "solutions"]}, "source": ["For $n=3$, we can explicitly calculate the thermodynamics of the system. By enumerating all the microstates, find the energy spectrum of the system. Plot the Boltzmann entropy (i.e. the log-degeneracy) at each allowed energy. \n", "\n", "Time how long this takes. How long would it take to do this for $n=4$?"]}, {"cell_type": "code", "metadata": {}, "source": ["#Write your answer here"], "outputs": [], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": ["### 2p. "]}, {"cell_type": "markdown", "metadata": {"flags": ["problems", "solutions"]}, "source": ["Using the explicit energy spectrum you found, find and plot the exact energy $E(T)$, entropy $S(T)$, and heat capacity $C_v(T)$. Check that the entropy has the expected values in the high-temperature and low-temperature limits. What difference does it make to each of the quantities whether or not we choose to count solutions that are rotations/reflections of each other as distinct?\n", "\n", "On the same plots, plot numerical estimates of the same quantities obtained from a simulated annealing run. How reliable is the data from the annealing run?\n", "\n", "Hints: Theoretically, all of these can obtained from the partition function: $F=-T\\log Z$, $S=-\\frac{\\partial F}{\\partial T}$, $E=-\\frac{\\partial \\log Z}{\\partial \\beta}$, $C_v=\\frac{\\partial E}{\\partial T}$. However, on the computer, avoid finite differencing by re-evaluating the sum over the energy spectrum for each quantity to be plotted. For the annealing estimates, you might want to cool more slowly than you were earlier since our objective is now to get data, rather than find the solution."]}, {"cell_type": "code", "metadata": {}, "source": ["#Write your answer here"], "outputs": [], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": ["### 2q. "]}, {"cell_type": "markdown", "metadata": {"flags": ["problems", "solutions"]}, "source": ["Suppose we wanted to use simulated annealing to find out _how many_ magic squares of a given order exist. By making a large number of annealing runs, provide a lower bound on the number of solutions for $n=4$. How long does it take for you find each solution?\n", "\n", "Hint: don't forget to check if the solutions are distinct upto rotations/reflections."]}, {"cell_type": "code", "metadata": {}, "source": ["#Write your answer here"], "outputs": [], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": ["### 2r. "]}, {"cell_type": "markdown", "metadata": {"flags": ["problems", "solutions"]}, "source": ["Suppose there are actually $t$ solutions, and each solution is equally likely. Show the expected number of successful annealing runs $m$ required to find all the solutions is $\\langle m\\rangle = t H_t$, where $H_t = 1+\\frac{1}{2}+\\frac{1}{3}+\\ldots+\\frac{1}{t}$ is the $t^{\\rm th}$ harmonic number.\n", "\n", "Hint: Find the expected number of trials to find the next distinct solution having found $n$ solutions, and sum these over $n$."]}, {"cell_type": "markdown", "metadata": {}, "source": ["Write your answer here"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### 2s. "]}, {"cell_type": "markdown", "metadata": {"flags": ["problems", "solutions"]}, "source": ["For the $n=4$ magic square, there are in fact 880 distinct (upto rotation/reflection) solutions. Find the expected number of runs required to find all of them, and estimate how long this would take."]}, {"cell_type": "markdown", "metadata": {}, "source": ["Write your answer here"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### 2t. "]}, {"cell_type": "markdown", "metadata": {"flags": ["problems", "solutions"]}, "source": ["In the previous question, we assumed we are equally likely to converge to any solution. Based on your observed counts of $n=4$ magic squares, does it seem like the simulated annealing algorithm is indeed equally likely to find any solution? Comment on the estimate of the time required to find all the solutions."]}, {"cell_type": "code", "metadata": {}, "source": ["#Write your answer here"], "outputs": [], "execution_count": null}], "metadata": {"kernelspec": {"display_name": "Python [default]", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.8"}}, "nbformat": 4, "nbformat_minor": 2}